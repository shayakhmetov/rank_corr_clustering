{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.17.1', '0.17', '1.10.4')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import DBSCAN, KMeans, SpectralClustering\n",
    "import os, gc, re\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "pl.rcParams['figure.figsize'] = 15, 5\n",
    "pd.__version__, sklearn.__version__, np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory_usage(df, ret=False, print_usage=True):\n",
    "    if type(df) == pd.core.frame.DataFrame:\n",
    "        m = df.memory_usage(index=True, deep=True).sum()/2**20\n",
    "    elif type(df) == np.ndarray:\n",
    "        m = df.nbytes/2**20\n",
    "    else:\n",
    "        m = df.data.nbytes/2**20\n",
    "    if print_usage:\n",
    "        print(m, 'Mb,', 'with shape =', df.shape)\n",
    "    if ret:\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_tosvmr(filename):\n",
    "    if os.stat(filename).st_size == 0:\n",
    "        return None\n",
    "    df = pd.read_csv(filename, sep=' ', header=None)\n",
    "    del df[7], df[6]\n",
    "    df.columns = ['Rank', 'QueryID', 'CTR', 'CTP',\n",
    "                  'Purchases', 'Turnover', 'ItemID']\n",
    "    df.QueryID = df.QueryID.str.extract('qid:(\\d+)').astype('int32')\n",
    "    df.Rank = df.Rank.astype('int8')\n",
    "    for i, col in enumerate(['CTR', 'CTP', 'Purchases', 'Turnover']):\n",
    "        df[col] = df[col].str.extract(str(i+1) + ':(.+)').astype('float16')\n",
    "    df.ItemID = df.ItemID.str.extract('item_id=(.+)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "directory = '../data/svmr/'\n",
    "size = 0\n",
    "records = 0\n",
    "# max_Rank, max_QID, max_ItemID_len = 0, 0, 0 # (2, 309111, 36)\n",
    "# min_Rank, min_QID, min_ItemID_len = (2**63-1,)*3 # (1, 2, 36)\n",
    "for i, filename in enumerate([f for f in os.listdir(directory) if re.match('.+\\.tosvmr', f)]):\n",
    "    chunk = read_tosvmr(os.path.join(directory, filename))\n",
    "    if chunk is not None:\n",
    "        qid = chunk.groupby('QueryID').Rank.agg('unique')\n",
    "        qids = chunk.groupby('QueryID').Rank.nunique() > 1\n",
    "        qids = set(qids[qids].index)\n",
    "        chunk = chunk.ix[chunk.QueryID.isin(qids), ['Rank', 'QueryID', 'ItemID']]\n",
    "        data = data.append(chunk)\n",
    "        size += memory_usage(chunk, ret=True, print_usage=False)\n",
    "        records += chunk.shape[0]\n",
    "        if i % 20 == 0:\n",
    "            print(i+1, 'file', filename)\n",
    "            print('memory =', size, 'Mb', 'Records =', records)\n",
    "    del chunk\n",
    "print('TOTAL', 'memory =', size, 'Mb. Records =', records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('../data/data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = read_tosvmr('../data/svmr/111AF73E-67E3-4E6E-BB32-3A7FB9B2F08A.tosvmr')\n",
    "# qid = data.groupby('QueryID').Rank.agg('unique')\n",
    "# qids = data.groupby('QueryID').Rank.nunique() > 1\n",
    "# qids = set(qids[qids].index)\n",
    "# data = data.ix[data.QueryID.isin(qids)]\n",
    "# memory_usage(data)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2201.1405811309814 Mb, with shape = (21774181, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>QueryID</th>\n",
       "      <th>ItemID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3220</td>\n",
       "      <td>B4180163-1E4B-4B7C-975E-7C99444C777B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3220</td>\n",
       "      <td>C19DF510-FD11-41AD-A794-2A1A58A4B9EF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3220</td>\n",
       "      <td>3FAFD53D-066E-49FA-B1DD-34ED9E592A17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3220</td>\n",
       "      <td>5978FEBB-DB0D-4EE9-B2E8-C5CAFEE23279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3220</td>\n",
       "      <td>A31CFDA1-CFA2-4AA8-836D-783DBE451694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank  QueryID                                ItemID\n",
       "0     1     3220  B4180163-1E4B-4B7C-975E-7C99444C777B\n",
       "1     1     3220  C19DF510-FD11-41AD-A794-2A1A58A4B9EF\n",
       "2     1     3220  3FAFD53D-066E-49FA-B1DD-34ED9E592A17\n",
       "3     1     3220  5978FEBB-DB0D-4EE9-B2E8-C5CAFEE23279\n",
       "4     1     3220  A31CFDA1-CFA2-4AA8-836D-783DBE451694"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/data.csv', dtype={'QueryID': 'int32', 'Rank': 'int8'})\n",
    "memory_usage(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.512625694274902 Mb, with shape = (66660, 405632)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<66660x405632 sparse matrix of type '<class 'numpy.int8'>'\n",
       "\twith 21509047 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queryID_encoder, itemID_encoder = LabelEncoder(), LabelEncoder()\n",
    "S = scipy.sparse.coo_matrix((data.Rank.values, \n",
    "                             (queryID_encoder.fit_transform(data.QueryID.values),\n",
    "                              itemID_encoder.fit_transform(data.ItemID.values)))).tocsr()\n",
    "memory_usage(S)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kendalltau_distance(x, y):\n",
    "    mask_x = np.in1d(x.indices, y.indices)\n",
    "    mask_y = np.in1d(y.indices, x.indices)\n",
    "    vector_x = x.data[mask_x]\n",
    "    vector_y = y.data[mask_y]\n",
    "    intersection_size = mask_x.sum()\n",
    "    if np.unique(vector_x).shape[0] == 1 or np.unique(vector_y).shape[0] == 1:\n",
    "        vector_x = np.append(vector_x, [0])\n",
    "        vector_y = np.append(vector_y, [0])\n",
    "    if intersection_size == 0:\n",
    "        tau = 0\n",
    "    else:\n",
    "        tau, pvalue = scipy.stats.kendalltau(vector_x, vector_y)\n",
    "    return 2 - tau - intersection_size/np.max([x.data.shape[0], y.data.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = S[:2000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%prun distance_matrix = sklearn.metrics.pairwise_distances(X, metric=kendalltau_distance)\n",
    "print('is there a nan value? ', np.isnan(distance_matrix).any())\n",
    "memory_usage(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('../data/distance_matrix.csv', distance_matrix, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, bins, patches = pl.hist(np.ravel(distance_matrix), bins=40)\n",
    "pl.xlabel('distance')\n",
    "pl.ylabel('number of objects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_silhouettes(silhouette_values, labels):\n",
    "    clusters = np.unique(labels)\n",
    "    pl.figure(figsize=(15, 20))\n",
    "    pl.title(str(clusters.shape[0]) + ' clusters. Avg silhouette =' + ('%.5f' % silhouette_values.mean()))\n",
    "    y_lower = 20\n",
    "    for i in clusters:\n",
    "        cluster_silhouette_values = np.sort(silhouette_values[labels == i])\n",
    "        y_upper = y_lower + cluster_silhouette_values.shape[0]\n",
    "\n",
    "        cluster_silhouette_values = np.sort(silhouette_values[labels == i])\n",
    "        pl.fill_betweenx(np.arange(y_lower,y_upper),\n",
    "                           0, cluster_silhouette_values, facecolor=pl.cm.spectral(i/clusters.shape[0]), alpha=0.6)\n",
    "        pl.text(-0.05, y_lower + 0.5 * cluster_silhouette_values.shape[0], str(i))\n",
    "        y_lower = y_upper + 10\n",
    "    pl.axvline(x=silhouette_values.mean(), color=\"red\", linestyle=\"--\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustering = DBSCAN(metric='precomputed', eps=0.9, min_samples=5)\n",
    "labels = clustering.fit_predict(distance_matrix)\n",
    "pd.Series(labels).value_counts().sort_index().plot(kind='bar', figsize=(15, 3))\n",
    "pl.xlabel('cluster')\n",
    "pl.ylabel('number of objects')\n",
    "silhouette_values = sklearn.metrics.silhouette_samples(distance_matrix, labels, metric='precomputed')\n",
    "print('silhouette =', silhouette_values.mean(), '\\nCluster == -1 is a noise')\n",
    "plot_silhouettes(silhouette_values, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans with SVD and euclidian metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u,s,v = scipy.sparse.linalg.svds(X.astype('f'), k=5)\n",
    "u.shape, s.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ks = np.arange(2,25)\n",
    "silhouettes = np.zeros(ks.shape[0])\n",
    "for i, k in enumerate(ks):\n",
    "    clustering = KMeans(n_clusters=k)\n",
    "    labels = clustering.fit_predict(u)\n",
    "    silhouettes[i] = sklearn.metrics.silhouette_score(u, labels)\n",
    "    print(k, silhouettes[i])\n",
    "pl.plot(ks, silhouettes, '--*')\n",
    "pl.xlabel('alpha')\n",
    "pl.ylabel('average silhouette')\n",
    "n_clusters = ks[np.argmax(silhouettes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustering = KMeans(n_clusters=n_clusters)\n",
    "labels = clustering.fit_predict(u)\n",
    "pd.Series(labels).value_counts().sort_index().plot(kind='bar', figsize=(15, 3))\n",
    "pl.xlabel('cluster')\n",
    "pl.ylabel('number of objects')\n",
    "silhouette_values = sklearn.metrics.silhouette_samples(u, labels)\n",
    "plot_silhouettes(silhouette_values, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustering = KMeans(n_clusters=n_clusters)\n",
    "labels = clustering.fit_predict(u)\n",
    "df = pd.DataFrame(u)\n",
    "df['labels'] = labels\n",
    "sns.pairplot(df, hue='labels')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
